{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3e403a4-c1fb-409e-aa18-ae5f697d8aa7",
   "metadata": {},
   "source": [
    "# <strong> A - Importation de modules </strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "978c0c1f-5af0-44b7-993f-0f548d9b85fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from P6_01_My_functions_Kengni_zanguim_Brice_062022.ipynb\n"
     ]
    }
   ],
   "source": [
    "############################################\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "############################################\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn import cluster , metrics\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn import manifold, decomposition\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "############################################\n",
    "import seaborn as sns\n",
    "#%matplotlib inline\n",
    "#%matplotlib notebook\n",
    "sns.set()\n",
    "\n",
    "###########################################\n",
    "import import_ipynb\n",
    "from P6_01_My_functions_Kengni_zanguim_Brice_062022 import *\n",
    "\n",
    "##########################################\n",
    "PATH_IMAGE =  \"/media/brice_kengni_zanguim/Samsung_T5/Téléchargements/photos\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591afd06-95fe-4c0e-8997-8189720960e4",
   "metadata": {},
   "source": [
    "# <strong> B - Importation de données </strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2afdab5d-a096-4d38-9952-e8959dcd2781",
   "metadata": {},
   "outputs": [],
   "source": [
    "picts = pd.read_csv(\"photos_leger.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4f2d24f-c951-4e34-b31f-49452615a81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = preprocessing.LabelEncoder().fit(picts.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bb749e3-0be3-4004-932c-65757e541a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_idx , _ = get_train_test_index( picts, 'label', (800,1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cfc52aa-9262-407b-aed3-98544f631a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "picts = picts.loc[sub_idx,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b8fb5e3-d3a9-489d-987c-81fc1a0103ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape : (4000, 2) \n"
     ]
    }
   ],
   "source": [
    "print( f\"Shape : {picts.shape} \" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0cc075d-1b00-4fc5-af40-a050710e2b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "picts = load_images( picts )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2105d44d-8b07-43bc-b34a-4dfcdc0eab65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape : (4000, 3) \n"
     ]
    }
   ],
   "source": [
    "print( f\"Shape : {picts.shape} \" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba5fb5d0-6e50-4d76-9da2-186874e6c871",
   "metadata": {},
   "outputs": [],
   "source": [
    "picts = process_images( picts , 'images', 'RGEC', (90,90) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06d21bba-9679-4a98-b0ef-56a7a2395fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx, test_idx = get_train_test_index( picts,\"label\" , (0.8 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25e901ed-670c-4650-8d22-ad2cacf01163",
   "metadata": {},
   "outputs": [],
   "source": [
    "picts ,picts_test = picts.loc[train_idx,:], picts.loc[test_idx,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e31b0fc5-6107-4da4-b224-586ddaabc821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- train shape : (3200, 4) \n",
      "- Test shape : (800, 4)\n"
     ]
    }
   ],
   "source": [
    "print( f\"- train shape : {picts.shape} \\n- Test shape : {picts_test.shape}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aff6f3f8-b68b-421f-9dc8-3fb36b21a332",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray( [ i  for i in picts.images_process] )/255.\n",
    "X_test = np.asarray( [ i for i in picts_test.images_process] )/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5e3122c-19b7-4014-9ad0-da5df79edec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "True_label = label_encoder.transform(picts.label)\n",
    "True_label_test =label_encoder.transform(picts_test.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca3925c4-ff34-4667-aa2a-aff4b4be39ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = True_label.astype(float)\n",
    "Y_test = True_label_test.astype(float)\n",
    "#Y , Y_test = Y.reshape((1,Y.size)) , Y_test.reshape((1,Y_test.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b529a7-7540-4618-a294-117f8d91f918",
   "metadata": {},
   "source": [
    "# <strong> J -  Convolutional Neural Network </strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f2c03e7-4489-498c-88b5-eea5eb193061",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_neural_network () :\n",
    "    model = keras.Sequential([\n",
    "    \n",
    "    # Première couche de convolution\n",
    "    keras.layers.Conv2D(filters=60, kernel_size= 3, activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(3,3) , strides=2), \n",
    "        \n",
    "    # Première couche de convolution\n",
    "    keras.layers.Conv2D(filters=120, kernel_size= 3, activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(3,3) , strides=2),\n",
    "        \n",
    "    # Fully Connected Classifier ( couche de réseau de Neuronnes denses )\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(524, activation=\"relu\"),\n",
    "    keras.layers.Dense(524, activation=\"relu\"),\n",
    "    keras.layers.Dense(5, activation=\"softmax\"),\n",
    "    \n",
    "    ])\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8dc80f3-32e3-42ee-a8c7-48d7ee3c5b4d",
   "metadata": {},
   "source": [
    "### <strong> J.1 -  Convertion des images en array </strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5968a7e9-e7a7-4ce7-ac67-d959ae741463",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-31 13:54:06.581676: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-31 13:54:06.583713: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "30/30 [==============================] - 24s 796ms/step - loss: 2.0125 - accuracy: 0.2525 - val_loss: 1.3809 - val_accuracy: 0.4200\n",
      "Epoch 2/12\n",
      "30/30 [==============================] - 25s 823ms/step - loss: 1.3081 - accuracy: 0.4696 - val_loss: 1.2793 - val_accuracy: 0.4638\n",
      "Epoch 3/12\n",
      "30/30 [==============================] - 24s 791ms/step - loss: 1.1526 - accuracy: 0.5529 - val_loss: 1.1626 - val_accuracy: 0.5412\n",
      "Epoch 4/12\n",
      "30/30 [==============================] - 21s 718ms/step - loss: 0.9441 - accuracy: 0.6408 - val_loss: 1.1760 - val_accuracy: 0.5562\n",
      "Epoch 5/12\n",
      "30/30 [==============================] - 21s 715ms/step - loss: 0.7740 - accuracy: 0.7163 - val_loss: 1.1452 - val_accuracy: 0.5788\n",
      "Epoch 6/12\n",
      "30/30 [==============================] - 21s 696ms/step - loss: 0.6117 - accuracy: 0.7758 - val_loss: 1.2929 - val_accuracy: 0.5525\n",
      "Epoch 7/12\n",
      "30/30 [==============================] - 21s 713ms/step - loss: 0.4108 - accuracy: 0.8571 - val_loss: 1.4113 - val_accuracy: 0.5750\n",
      "Epoch 8/12\n",
      "30/30 [==============================] - 21s 705ms/step - loss: 0.2567 - accuracy: 0.9208 - val_loss: 1.5596 - val_accuracy: 0.5875\n",
      "Epoch 9/12\n",
      "30/30 [==============================] - 22s 724ms/step - loss: 0.1378 - accuracy: 0.9604 - val_loss: 1.7747 - val_accuracy: 0.5425\n",
      "Epoch 10/12\n",
      "30/30 [==============================] - 22s 739ms/step - loss: 0.0533 - accuracy: 0.9883 - val_loss: 2.1131 - val_accuracy: 0.5537\n",
      "Epoch 11/12\n",
      "30/30 [==============================] - 21s 716ms/step - loss: 0.0268 - accuracy: 0.9962 - val_loss: 2.1766 - val_accuracy: 0.5525\n",
      "Epoch 12/12\n",
      "30/30 [==============================] - 21s 717ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 2.3899 - val_accuracy: 0.5638\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8efe9f0730>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNN = generate_neural_network()\n",
    "\n",
    "CNN.compile( optimizer= \"adam\", loss= keras.losses.sparse_categorical_crossentropy ,metrics = [\"accuracy\"])\n",
    "\n",
    "CNN.fit( X , Y ,  epochs = 12 , batch_size = 80 , validation_split = 0.25 , use_multiprocessing = True )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a38d581-3e3e-4ee8-8f66-b037f04ccebc",
   "metadata": {},
   "source": [
    "# <strong> K -  Transfert Learning </strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "73d80119-953f-4e15-8ff1-6e66432f8e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "modele_de_base = tf.keras.applications.MobileNet( include_top= False , input_shape= X[0].shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "19559b47-b00d-441c-a9df-f1d625ca9cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "entrainer_le_modèle_de_base = ( True , 50 )\n",
    "\n",
    "modele_de_base.trainable = False\n",
    "\n",
    "if entrainer_le_modèle_de_base[0] :\n",
    "    for layer in modele_de_base.layers[-entrainer_le_modèle_de_base[1] : ] :\n",
    "        layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "0f5e8660-1431-4a18-9877-d07d42915b2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#modele_de_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "d4b82a14-48e1-4954-bef8-4fae579ce074",
   "metadata": {},
   "outputs": [],
   "source": [
    "couche_a_entrainer = keras.Sequential()\n",
    "\n",
    "#couche_a_entrainer.add( keras.layers.MaxPool2D() )\n",
    "couche_a_entrainer.add( keras.layers.Flatten() )\n",
    "\n",
    "couche_a_entrainer.add( keras.layers.Dense(25, activation=\"tanh\"),)\n",
    "couche_a_entrainer.add( keras.layers.Dense(5, activation=\"softmax\"),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "cb83e1a9-8693-4ac7-aded-873c025ae59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_transfert_learning = keras.Sequential( [modele_de_base, couche_a_entrainer] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "2ce4607c-ad0d-4115-b9ce-e807aec48cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenet_1.00_224 (Functio  (None, 2, 2, 1024)       3228864   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " sequential_28 (Sequential)  (None, 5)                 102555    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,331,419\n",
      "Trainable params: 102,555\n",
      "Non-trainable params: 3,228,864\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "CNN_transfert_learning.compile( optimizer= \"adam\", loss= keras.losses.sparse_categorical_crossentropy ,metrics = [\"accuracy\"])\n",
    "\n",
    "CNN_transfert_learning.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "f118c22d-54d8-4872-b290-5367d3b896dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.drop of Empty DataFrame\n",
       "Columns: []\n",
       "Index: []>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame().drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "7af89f89-697f-40e1-995d-e89eebe77408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "10/10 [==============================] - 9s 835ms/step - loss: 1.3922 - accuracy: 0.4592 - val_loss: 0.9678 - val_accuracy: 0.6479\n",
      "Epoch 2/16\n",
      "10/10 [==============================] - 8s 809ms/step - loss: 0.7413 - accuracy: 0.7482 - val_loss: 0.7186 - val_accuracy: 0.7625\n",
      "Epoch 3/16\n",
      "10/10 [==============================] - 8s 779ms/step - loss: 0.5778 - accuracy: 0.8074 - val_loss: 0.7149 - val_accuracy: 0.7750\n",
      "Epoch 4/16\n",
      "10/10 [==============================] - 8s 820ms/step - loss: 0.4729 - accuracy: 0.8386 - val_loss: 0.7125 - val_accuracy: 0.7729\n",
      "Epoch 5/16\n",
      "10/10 [==============================] - 8s 791ms/step - loss: 0.4003 - accuracy: 0.8691 - val_loss: 0.7043 - val_accuracy: 0.7708\n",
      "Epoch 6/16\n",
      "10/10 [==============================] - 8s 811ms/step - loss: 0.3432 - accuracy: 0.9007 - val_loss: 0.7029 - val_accuracy: 0.7729\n",
      "Epoch 7/16\n",
      "10/10 [==============================] - 8s 767ms/step - loss: 0.2963 - accuracy: 0.9210 - val_loss: 0.6801 - val_accuracy: 0.7833\n",
      "Epoch 8/16\n",
      "10/10 [==============================] - 8s 822ms/step - loss: 0.2626 - accuracy: 0.9338 - val_loss: 0.6635 - val_accuracy: 0.7917\n",
      "Epoch 9/16\n",
      "10/10 [==============================] - 8s 822ms/step - loss: 0.2462 - accuracy: 0.9438 - val_loss: 0.6913 - val_accuracy: 0.7688\n",
      "Epoch 10/16\n",
      "10/10 [==============================] - 8s 823ms/step - loss: 0.2197 - accuracy: 0.9467 - val_loss: 0.6769 - val_accuracy: 0.7812\n",
      "Epoch 11/16\n",
      "10/10 [==============================] - 7s 742ms/step - loss: 0.1883 - accuracy: 0.9621 - val_loss: 0.6457 - val_accuracy: 0.7979\n",
      "Epoch 12/16\n",
      "10/10 [==============================] - 8s 785ms/step - loss: 0.1745 - accuracy: 0.9688 - val_loss: 0.6477 - val_accuracy: 0.8000\n",
      "Epoch 13/16\n",
      "10/10 [==============================] - 8s 789ms/step - loss: 0.1693 - accuracy: 0.9684 - val_loss: 0.6567 - val_accuracy: 0.7979\n",
      "Epoch 14/16\n",
      "10/10 [==============================] - 8s 828ms/step - loss: 0.1618 - accuracy: 0.9706 - val_loss: 0.6633 - val_accuracy: 0.7958\n",
      "Epoch 15/16\n",
      "10/10 [==============================] - 8s 769ms/step - loss: 0.1479 - accuracy: 0.9735 - val_loss: 0.6695 - val_accuracy: 0.8083\n",
      "Epoch 16/16\n",
      "10/10 [==============================] - 8s 820ms/step - loss: 0.1507 - accuracy: 0.9735 - val_loss: 0.6676 - val_accuracy: 0.8000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8d9e08bd90>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNN_transfert_learning.fit( X , Y ,  epochs = 16, batch_size= 300, validation_split=0.15, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "a5fa301f-0319-4da6-8274-bff450e2bb53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5221333092564904"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [np.argmax(i ) for i in CNN_transfert_learning.predict( X_test ) ]\n",
    "metrics.adjusted_rand_score(Y_test , a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "3c30b71c-9c2b-49ab-80a3-ab7b3eff916f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7725"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score( a , Y_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c88f0d8-c811-4bff-8ef9-4bff8df37b66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a58c9b-5226-45d4-8c65-6c021b6349c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e437712f-3039-4c0c-9534-c95611257136",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
