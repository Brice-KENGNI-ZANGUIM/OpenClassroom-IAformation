{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09a70b9c-feff-4b73-8a38-e05259a0a7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "# import the KNNimputer class\n",
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "586cd510-e257-4339-af31-5b7bdb4a4734",
   "metadata": {},
   "outputs": [],
   "source": [
    "def couleur_léatoire_hex() :\n",
    "    \"\"\"\n",
    "    Générateur de couleur aléatoire dans le format hexadecimal\n",
    "\n",
    "    paramètres :  \n",
    "    ------------\n",
    "        Aucun paramètre à fournir\n",
    "\n",
    "    Returns : \n",
    "    ---------\n",
    "        String : Code hexadecimal de la couleur fabriquée sous forme d'une variable chaine de caractères.\n",
    "    \"\"\"\n",
    "    s = \"#\"\n",
    "    a = np.random.choice([\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"A\",\"B\",\"C\",\"D\",\"E\",\"F\"] , 6 ,replace=False)\n",
    "    for i in a : s += i\n",
    "    return s\n",
    "\n",
    "def camemberg ( labels = [\"Brice\",\"Romeo\",\"Marthe\",\"Franck\",\"Arnaud\"] , sizes=[28,18,23,30,15] ,titre = \"CAMENBERG\", figure_size =(8,8) , rot = 30 ) :\n",
    "    \"\"\"\n",
    "    La fonction permet d'afficher un camemberg selon les entrée fournies\n",
    "    \n",
    "    Paramètre :\n",
    "    -----------\n",
    "        labels : Array_like \n",
    "                Labels des données à afficher sous forme de camemberg\n",
    "        sizes :  Array_like \n",
    "                Grandeurs quantitatives correspondants aux labels fournis\n",
    "        titre : str\n",
    "                Titre du graphique\n",
    "        figure_size : tuple\n",
    "                respectivement la largeur et la hauteur du graphique sous forme de tuple\n",
    "        \n",
    "    Return :\n",
    "    --------\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Data to plot\n",
    "    label = np.array(labels)\n",
    "    size = np.array(sizes)\n",
    "    colors = [couleur_léatoire_hex() for i in range(size.size) ]\n",
    "    explode = np.array([ 0. for i in range(size.size) ])  # explode 1st slice\n",
    "    explode[size == size.max()] = 0.08\n",
    "\n",
    "    # Plot\n",
    "    plt.figure( figsize = figure_size )\n",
    "    plt.title(titre, color ='brown' , size = 18 )\n",
    "    plt.pie(size, explode=explode, labels=label, colors=colors, autopct='%1.1f%%', shadow=True, startangle=rot, textprops={'fontsize': figure_size[0]*2})\n",
    "    plt.axis('equal')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def nan_proportion ( data , figsize=( 7 , 7 ) , titre = \"\\nValeurs manquantes et infinies dans les données brutes\\n\" , rot = 15 ):\n",
    "    \"\"\"\n",
    "    La fonction trace un Camemberg donnant les proportions de valeurs manquantes infinies et finies adans les données\n",
    "    \n",
    "    Paramètres :\n",
    "    ------------\n",
    "        data : pandas.core.frame.DataFrame\n",
    "            Données à utilisée par la fonction sous forme d'un DataFrame de la bibliothès pandas                \n",
    "        figsize : tuple\n",
    "            respectivement la largeur et a hauteur du camemberg à représenter\n",
    "            \n",
    "    return :\n",
    "    --------\n",
    "            None\n",
    "    \"\"\"\n",
    "    a =  data.isna().mean().mean()\n",
    "    b = data.isin([np.inf,-np.inf]).mean().mean()\n",
    "    camemberg(sizes = [ a , b , 1-a-b ] , labels = [\"NAN\",\"Infinie\",\"Valeurs Finies\"] ,titre = titre,figure_size=figsize , rot = rot)\n",
    "    \n",
    "def plot_nan_proportion( data ,  plt_type = \"lns\", n_bar = 30, figsize = (7,7)) :\n",
    "    \"\"\"\n",
    "    Traces l'Histogramme de la distribution des valeurs manquantes par colonne ou par ligne des données fournies à la fonction\n",
    "    \n",
    "    Paramètres :\n",
    "    ------------\n",
    "        data :  pandas.core.frame.DataFrame\n",
    "            Données à utilisée par la fonction sous forme d'un DataFrame de la bibliothès pandas\n",
    "        plt_type :  str\n",
    "            type de répresentation à réaliser. peut prendre les valeurs \"lns\" et \"col\" respectivement pour une représentation des valeurs manquantes par lignes(\"lns\") ou par colonnes(\"col\")\n",
    "            La valeur par defaut est \"lns\"\n",
    "        n_bar : int\n",
    "            Nonbre de barres dans l'histogramme à afficher. Corresponds au paramètre \"bins\" de la methode plt.hist()            \n",
    "        figsize : tuple\n",
    "            respectivement la largeur et a hauteur du camemberg à représenter\n",
    "            \n",
    "    Return :\n",
    "    --------\n",
    "        None\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    if plt_type ==\"col\" :\n",
    "        sns.displot( data.isna().mean()*100, kde=True,color=couleur_léatoire_hex() , bins=n_bar, height=figsize[1], aspect=figsize[0]/figsize[1] )\n",
    "        plt.xlabel('valeurs manquantes (% )', size= 15)\n",
    "        plt.ylabel(\"Nombre de variables\", size =15)\n",
    "        plt.title(\"Proportions de valeurs manquantes sur les colonnes\",size=25)\n",
    "        plt.show()\n",
    "    elif plt_type == \"lns\": \n",
    "        sns.displot( data.isna().mean(axis=1)*100, kde=True,color=couleur_léatoire_hex(), bins=n_bar, height=figsize[1], aspect=figsize[0]/figsize[1] )\n",
    "        plt.xlabel('valeurs manquantes (% )', size= 15)\n",
    "        plt.ylabel(\"Nombre de Lignes\", size =15)\n",
    "        plt.title(\"Proportions de valeurs manquantes sur les lignes\",size=25)\n",
    "        plt.show()\n",
    "        \n",
    "def tableau_valeur_manquante(data):\n",
    "        \"\"\"\n",
    "        La fonction renvoie un DataFrame panda qui fournie le nombre et le pourcentage des valeurs manquantes et infinies pour chaque colonnes\n",
    "        Les variables sont ensuite ordonnées selon les valeurs décroissantes du nombre de valeurs manquantes trouvées\n",
    "        \n",
    "        Paramètres :\n",
    "            None\n",
    "        ------------\n",
    "            data : pandas.core.frame.DataFrame\n",
    "                Dataframe à utiliser dans la fonction pour le calcul des valeurs manquantes et infinies\n",
    "        \"\"\"\n",
    "        # Construction du tableau de valeurs manquantes et leur pourcentage pour chaque colonne et Réattribution des noms aux colonnes du tableau\n",
    "        mis_val_table = pd.concat([ data.isin([np.inf,-np.inf]).sum() , data.isnull().sum() , 100*data.isin([np.inf,-np.inf]).mean() , 100*data.isnull().mean()  ] , axis=1)\n",
    "        mis_val_table = mis_val_table.rename( columns = { 0 : \"Nb de valeurs infinies\" , 1 : \"Nb de Valeurs manquantes\", 2 : \"Inf Proportions ( % )\", 3 : \"Nan Proportions ( % )\" } )\n",
    "        \n",
    "        # Sort the table by percentage of missing descending\n",
    "        mis_val_table = mis_val_table.sort_values( by = \"Nan Proportions ( % )\" ,axis =0 ,ascending=False).round(2)\n",
    "        \n",
    "        return mis_val_table \n",
    "\n",
    "def print_features_importances( model, X , n = 20 ,figsize = (20,15), get_importance = False ,error_raise = False) :\n",
    "    \"\"\"\n",
    "    La fonction permet d'afficher l'importance globale de variables pour un modèle donnée de machine leaning \n",
    "    \n",
    "    paramètres :\n",
    "    ------------\n",
    "        model : machine learning model \n",
    "            modèle a utiliser pour la recherche de l'importante de variables/features\n",
    "        X : pandas.core.frame.DataFrame\n",
    "            données à fournir au modèle\n",
    "        n : int \n",
    "            nombre de variables à afficher la valeur par defaut est de 10\n",
    "        figsize : tuple\n",
    "            respectivement la largeur et la hauteur du graphique qui sera affiché. la valeur par defaut est (20,15)\n",
    "        get_importance : bool\n",
    "            Dire si la fonction doit ou non renvoyer la liste des features importances. La valeur par defaut est False   \n",
    "        error_raise : bool\n",
    "            Dire si le programme doit continuer de tourner ou interrompre son excussion quand elle rencontre une erreure.\n",
    "            La valeur par defaut est False\n",
    "    \n",
    "    return :\n",
    "    --------\n",
    "        importance_features : Array_like\n",
    "    \n",
    "    Raises:\n",
    "    -------\n",
    "        AttributeError : Une exception est eventuellement levée lorsque lorsque le modèle fourni ne possède pas d'attribut 'features_importances_'\n",
    "    \"\"\"\n",
    "    # Acquisition de l'importance des fetaures\n",
    "    try :\n",
    "        importance = model.feature_importances_\n",
    "    except AttributeError:\n",
    "        if error_raise : \n",
    "            raise AttributeError(\"Le modèle que vous avez fourni ne possède pas l'attribut 'features_importances_'\")\n",
    "        else :\n",
    "            print(\"Le modèle que vous avez fourni ne possède pas l'attribut 'features_importances_'\")\n",
    "        return\n",
    "    \n",
    "    \n",
    "    importance /= max(importance)\n",
    "    # création du dataframe\n",
    "    importance_features = pd.DataFrame({ \"Features\" : X.columns ,\"Importance\": importance }) \n",
    "    # Triage par ordre d'importance\n",
    "    importance_features.sort_values(by=\"Importance\", inplace=True, ascending=True)                     \n",
    "\n",
    "    plt.figure(figsize= figsize)\n",
    "    plt.barh(importance_features.iloc[-n:,0],importance_features.iloc[-n:,1], color = [couleur_léatoire_hex() for i in range(n)])\n",
    "    plt.title(\"\\nImportance des différentes variables\", size = 2*figsize[0])\n",
    "    plt.xlabel(\"Importance\" , size = 1.5*figsize[0])\n",
    "    plt.show()\n",
    "    if get_importance : \n",
    "        return importance_features     \n",
    "\n",
    "def concentration_gini ( data) :\n",
    "    \"\"\"\n",
    "    Mesure de concentration des données selon le modèle de Gini\n",
    "    \n",
    "    Paramètres :\n",
    "    ------------\n",
    "        data : pandas.core.frame.DataFrame\n",
    "            données a utiliser par la fonction\n",
    "            \n",
    "    Return :\n",
    "    --------\n",
    "        gini : float\n",
    "    \n",
    "    \"\"\"\n",
    "    data = data[~data.isna().values]\n",
    "    data =  np.append(0, np.cumsum( np.sort(data) )/data.sum())\n",
    "    gini = 2*( 0.5 - ( data.sum() - 0.5*data[-1] - 0.5*data[0] )/data.size  )\n",
    "    return gini\n",
    "\n",
    "def concentration_brice ( data ):\n",
    "    \"\"\"\n",
    "    Mesure de concentration de données selon le modèle défini de Brice KENGNI ZANGUIM\n",
    "    \n",
    "    Paramètres :\n",
    "    ------------\n",
    "        data : pandas.core.frame.DataFrame\n",
    "            données a utiliser par la fonction\n",
    "            \n",
    "    Return :   float\n",
    "    -------- \n",
    "    \"\"\"\n",
    "    q_a , q_b, q_c = 0.8 , 0.5 , 0.2 # Quantilles extrêmes pris en compte\n",
    "    data = data[~data.isna().values]\n",
    "    box_over_domain = np.exp( -(q_a-q_b)*(q_a-q_c)*(q_b-q_c)  + \\\n",
    "                              ( np.quantile(data,q_a) - np.quantile(data,q_b) ) *  \\\n",
    "                              ( np.quantile(data,q_a) - np.quantile(data,q_c) ) *  \\\n",
    "                              ( np.quantile(data,q_b) - np.quantile(data,q_c) ) /  \\\n",
    "                              ( data.max() - data.min() )**3\n",
    "                             )\n",
    "    peer_to_peer_distance_mean =  1 #( data.max() - data.min()  )/data.size\n",
    "    distance_to_min_mean =  (data - data.min()).var()/(( data.max() - data.min() )**2/12. ) \n",
    "    return np.sqrt( box_over_domain*peer_to_peer_distance_mean*distance_to_min_mean  )\n",
    "\n",
    "def concentration ( data , mode = 'brice' , around = 5 ):\n",
    "    out = {}\n",
    "    df = pd.concat([data.select_dtypes(include=[float]), data.select_dtypes(include=[int])], axis=1)\n",
    "    for i in df.columns :\n",
    "        a =  data[i]\n",
    "        if mode =='brice' :\n",
    "            out[i] = round(concentration_brice(a) , around)\n",
    "        elif mode =='gini' :\n",
    "            out[i] = round(concentration_gini (a),around)\n",
    "        elif mode == 'both':\n",
    "            out[i] = round(concentration_brice(a)*concentration_gini (a)  , around)\n",
    "    return out\n",
    "\n",
    "def random_replace ( data , mask,std = 0.5) :\n",
    "    \"\"\"Generateur d'une liste de nombre aléatoires repartis dans un domaine entre la mediane et la moyenne des données\"\"\"\n",
    "    return abs( np.random.normal( 0.5*(data.median( ) + data.mean( ) ),\\\n",
    "                                   ( std*(data.quantile( 0.8 ) - data.quantile( 0.2 )) ) ,\\\n",
    "                                   ( mask.sum() ) \\\n",
    "                                   ) )\n",
    "\n",
    "def unique_boxplot(data , label ) :\n",
    "    data = data[~data.isna().values]\n",
    "    print(f\"\\n\\t\\tSize : {data.shape} - Mean : {round(data.mean(),2)} - Med : {round(data.median(),2)} -  IQR : {round(data.quantile(0.75) - data.quantile(0.25)  ,2)} -  Concentration : {round(concentration_brice(data),4)}\")\n",
    "    plt.figure(figsize=(18,2))\n",
    "    plt.boxplot(data, labels = label, vert =False, whis=1.5, showmeans =True, widths=0.4)\n",
    "    plt.ylabel('')\n",
    "    plt.title(f'Boxplot : {label[0]}' , size=15)\n",
    "    plt.show()\n",
    "\n",
    "def all_boxplots(data , type_var = \"float\" , limit = 0.1 , kind = 'min'):\n",
    "\n",
    "    if type_var ==\"float\" :\n",
    "        df = data.select_dtypes(include=[float])\n",
    "    elif type_var ==\"int\" :\n",
    "        df = data.select_dtypes(include=[int])\n",
    "    else :\n",
    "        df = data.select_dtypes(include=[float, int])\n",
    "        #df = pd.concat([data.select_dtypes(include=[float]), data.select_dtypes(include=[int])], axis=1)\n",
    "    if kind == 'max' :   # On affiche les boxplot de toutes les colonnes sans exception\n",
    "        for col in df.columns :\n",
    "            unique_boxplot( df[col] , [col] )\n",
    "    elif kind =='min' :  # On affiche uniquement les boxplot de colonnes avec une concentration inférieure à la limite établie\n",
    "        conc = concentration(df) \n",
    "        colons , mesure = list(conc.keys())  , list(conc.values())\n",
    "        mesure , colons = zip(*sorted(zip(mesure,colons) ,reverse=True))\n",
    "        mesure , colons = np.array(mesure) , np.array(colons)\n",
    "        if np.array(limit).size == 1 :\n",
    "            colons = colons[mesure <= limit]\n",
    "            for col in colons :\n",
    "                    unique_boxplot( df[col] , [col] )\n",
    "        elif np.array(limit).size == 2 :\n",
    "            colons = colons[(limit[0] <=mesure) & (mesure <= limit[1])]\n",
    "            for col in colons :\n",
    "                    unique_boxplot( df[col] , [col] )\n",
    "\n",
    "def plot_multiple_bar(data, group, observation, figsize = (9,6), show_count = True, normalize = True) :\n",
    "    group_x = np.array(data[group].value_counts().index) #; group_x = group_x[~np.isnan(group_x)]  # Différents groupes d'individus dans lesquels on regroupe les donnéesGroup d'individus \n",
    "    group_y = data[observation].value_counts().index  #; group_y = group_y[~np.isnan(group_y)]   #  Modalité qu'on observe pour chaque groupe d'individus\n",
    "    if normalize :                        # Nombre/Frequence de modalités pour chaque groupe d'individus\n",
    "        count = { j : [round(( (data[group]==i)&(data[observation]==j) ).mean(),6)   for i in group_x  ] for j in group_y  } \n",
    "    else :\n",
    "        count = { j : [( (data[group]==i)&(data[observation]==j) ).sum()   for i in group_x  ] for j in group_y  }\n",
    "    \n",
    "    x_axis = np.arange(group_x.size)\n",
    "    width = 1./(group_y.size+2)\n",
    "    plt.figure(figsize=figsize)\n",
    "    for k in range( group_y.size ):\n",
    "        pl = plt.bar( x_axis+width*(k-0.5*(group_y.size-1)), count[group_y[k]] ,width = width, label = group_y[k])\n",
    "        if show_count : \n",
    "            for bar in pl: plt.annotate(bar.get_height() , xy=(bar.get_x()+0.1*width , 1.01*bar.get_height()) , fontsize=12)\n",
    "    \n",
    "    plt.xticks(x_axis ,group_x)\n",
    "    plt.xlabel(group, size= 15)\n",
    "    plt.ylabel(\"Quantité\", size=15)\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    \n",
    "def density_compare(data , observation  , group , x_bornes = None) :\n",
    "    plt.figure(figsize=(10,7))\n",
    "    plt.title(f\"Distribution de Densité de {observation} par {group}\")\n",
    "    for i in data[group].unique() :\n",
    "        if i !=\"XNA\":\n",
    "            sns.kdeplot(data.loc[ data[group]== i  ,observation],label = f\"{group} = {i}\" , lw= 4  )\n",
    "            #sns.displot( data.loc[ data[group]== i  ,observation], kde=True,color='g', bins=120, height=7, aspect=1.7 ,label = i)\n",
    "    if x_bornes : plt.xlim(x_bornes[0] , x_bornes[1])\n",
    "    plt.legend(loc = 'best')\n",
    "    plt.ylabel(\"Distribution de densitié\" , size = 15)\n",
    "    plt.xlabel( observation , size=15)\n",
    "    plt.show()\n",
    "\n",
    "def get_train_test_dataframe ( data , seed = None , test_prop = 0.2, nan_in_test = False ) :\n",
    "    \"\"\"\n",
    "    La fonction réalise un split des données fournies en données de test et d'entraineemnt\n",
    "    \n",
    "    Paramètres :\n",
    "    ------------\n",
    "        data : pandas.core.frame.DataFrame\n",
    "            Donnée à utiliser dans l'execution de la fonction\n",
    "        seed : int\n",
    "        \n",
    "        test_prop : float\n",
    "            correspond à la proportion que doit avoir les données de test. \n",
    "            La valeur par defaut est de 0.2 et doit toujorus être comprise entre 0 et 1\n",
    "    \n",
    "    Return :  pandas.core.frame.DataFrame\n",
    "    --------\n",
    "        data_train \n",
    "        data_test\n",
    "    \n",
    "    \"\"\"\n",
    "    if nan_in_test :\n",
    "        test_mask = data.sample(frac = test_prop , random_state= seed ).index\n",
    "    else :\n",
    "        test_mask = data[data.isna().sum(axis=1) == 0].sample(n = int(test_prop*data.shape[0])).index\n",
    "    \n",
    "    return data.drop(test_mask, axis=0) , data.loc[test_mask,:]\n",
    "\n",
    "def print_confusion_matrix(confusion_matrix, class_names, figsize = (8,7), cmap = None): \n",
    "    import itertools\n",
    "    \n",
    "    \"\"\"\n",
    "    Affiche la transposée de la  matrice de confusion tel que fournie par \n",
    "    la fonction sklearn.metrics.confusion_matrix, sous forme de heatmap\n",
    "    \n",
    "    Paramètres :\n",
    "    ------------\n",
    "        confusion_matrix : Array_type\n",
    "            matrice de confusion\n",
    "        class_name : list or Array_type\n",
    "            label à attribuer aux observations : 0 - 1 , oui - non , bon - mauvais , ok - pas ok\n",
    "    \n",
    "    Return : None\n",
    "    --------\n",
    "    \n",
    "    \"\"\"    \n",
    "    confusion_matrix = confusion_matrix.T\n",
    "    with plt.style.context(('ggplot', 'seaborn')):\n",
    "        fig = plt.figure(figsize=figsize, num=1)\n",
    "        plt.imshow(confusion_matrix, interpolation='nearest',cmap= plt.cm.Blues )\n",
    "        plt.xticks([0,1],class_names , )\n",
    "        plt.yticks([0,1],class_names)\n",
    "        plt.xlabel('Vraie étiquette' , size = 3*np.min(figsize) )\n",
    "        plt.ylabel('Etiqeutte prédite' , size = 3*np.min(figsize))\n",
    "        for i, j in itertools.product(range(confusion_matrix.shape[0]), range(confusion_matrix.shape[1])):\n",
    "                    plt.text(j, i,confusion_matrix[i, j], horizontalalignment=\"center\",color=\"red\" , fontsize = 2.2*np.min(figsize))\n",
    "        plt.grid(None)\n",
    "        plt.title('Confusion Matrix' , fontsize = 4*np.min(figsize))\n",
    "        plt.colorbar() \n",
    "    \n",
    "def prediction_function_threshold ( model=None , X=None, Y_proba=None , seuil = 0.5 ) :\n",
    "    \"\"\"\n",
    "    La fonction permet d'évaluer la prediction d'un modèle donnée en fonction du modèle, de l'entrée, d'une probabilité fournie et d'un seuil \n",
    "    \n",
    "    Paramètres :\n",
    "    ------------\n",
    "        model : modèle de machine learning à utiliser.\n",
    "        X : pandas.core.frame.DataFrame\n",
    "            donnée à fournir au modèle pour la prédiction. Si model est fourni alors X doit aussi être fourni et dans ce cas Y_proba n'est pas utilisé.\n",
    "        Y_proba : Array_type\n",
    "            probabilité qu'un individu soit du label positif. Si Y_proba est fourni alors model et X ne sont pas utilisés\n",
    "        seuil : float\n",
    "            seuil de probalité à utiliser pour la calcul de la prediction. la valeur par defaus est 0.5 et doit toujours être comprise entre 0 et 1\n",
    "    \n",
    "    Return : Array_type\n",
    "        prediction\n",
    "        \n",
    "    \"\"\"\n",
    "    if ( type(model) == type(None) ) and ( type(X) == type(None) ): \n",
    "        return np.array( Y_proba > seuil , dtype = int)\n",
    "    else :\n",
    "        try : \n",
    "            return np.array( model.predict_proba(X)[:,1] > seuil , dtype = int)\n",
    "        except :\n",
    "            print(\"Le modèle que vous avez fourni ne possède pas de méthode 'predict_proba()'\")\n",
    "            return\n",
    "        \n",
    "#  Definition de la meilleure métrique \n",
    "#  Definition de la meilleure métrique \n",
    "def my_cost( y , y_pred , poids = 4  , seuil = np.linspace(0.08,0.9,100 ) , scorer = False ) : \n",
    "    \"\"\"\n",
    "    La fonction permet d'évaluer le cout métier d'un modèle donné \n",
    "    \n",
    "    Paramètres :\n",
    "    ------------\n",
    "        y : Array_like \n",
    "            vraie valeur labels pour chaque individus ou observations\n",
    "        y_pred : Array_like \n",
    "            vecteur probabilité ( d'être positif  ) peu aussi être le vecteur prediction du modèle pour chaque individus ou observations\n",
    "            \n",
    "    return : dict\n",
    "    ------------\n",
    "        out : dict \n",
    "        La dictionnaire renvoyé est de la forme : \n",
    "        { \"cout\" : Array_type de variation du coût en fonction du seuil , \"cout_min\" : valeur du coût minimal , \"seuil_min\" : seuil correspondant au cout minimal }\n",
    "    \"\"\"\n",
    "    if type(y) == type(pd.DataFrame()) :\n",
    "        label = pd.DataFrame( {\"Y_test\" : y.values.reshape( (y.shape[0],) ) , \"Y_prob\" : y_pred } )\n",
    "    else :\n",
    "        label = pd.DataFrame( {\"Y_test\" : y , \"Y_prob\" : y_pred } )\n",
    "\n",
    "    out = {\"cout\" : []}\n",
    "    if type(seuil) == type(0.2) : seuil = np.array([seuil])\n",
    "    for s in seuil : \n",
    "        label[\"Y_pred\"] = label[\"Y_prob\"].apply( lambda x : int(x > s))\n",
    "        label.loc[ (label[\"Y_test\"] ==0) & (label[\"Y_pred\"] == 0) , \"decision\"]  = \"VN\"\n",
    "        label.loc[ (label[\"Y_test\"] ==1) & (label[\"Y_pred\"] == 1) , \"decision\"]  = \"VP\"\n",
    "        label.loc[ (label[\"Y_test\"] ==0) & (label[\"Y_pred\"] == 1) , \"decision\"]  = \"FP\"\n",
    "        label.loc[ (label[\"Y_test\"] ==1) & (label[\"Y_pred\"] == 0) , \"decision\"]  = \"FN\"\n",
    "        out[\"cout\"].append( ( label[\"decision\"] == \"FP\" ).mean() + poids*( label[\"decision\"] == \"FN\" ).mean() )\n",
    "\n",
    "    out[\"cout\"] = np.array(out[\"cout\"])\n",
    "    if scorer : \n",
    "        return out[\"cout\"].min()\n",
    "    else : \n",
    "        out[\"cout_min\"] = out[\"cout\"].min()\n",
    "        out[\"seuil_min\"] = seuil[out[\"cout\"] == out[\"cout_min\"]]\n",
    "        out[\"cout\"] = list(out[\"cout\"])\n",
    "        return out\n",
    "        \n",
    "def print_scores(model = None , X_test=None , Y_true=None , Y_proba = None  , line_width = 6 , seuil = np.linspace( 0 , 0.9 , 90 ) , plot_kind = \"apr\", give_results = False , show_graph = True) :\n",
    "    scores = {} \n",
    "    beta = np.linspace( 0.7 , 2. , 2 )\n",
    "    if ( type(model)!=type(None) ) and ( type(X_test)!=type(None) ) and ( type(Y_proba) == type(None) ) :\n",
    "        try :\n",
    "            Y_proba = model.predict_proba(X_test)[:,1]\n",
    "        except :\n",
    "            print(\"Le modèle que vous avez fourni ne possède pas de méthode 'predict_proba'\")\n",
    "            return\n",
    "    \n",
    "    ## Pour chaque coefficient beta de F_beta score, je vais calculter la variation du F_beta score avec le seuil\n",
    "    if \"b\" in plot_kind :\n",
    "        for b in beta :\n",
    "            scores[f\"beta = {b}\"] = [  metrics.fbeta_score(Y_true , prediction_function_threshold(Y_proba = Y_proba ,seuil = s) , beta = b ) for s in seuil ]\n",
    "    if \"a\" in plot_kind :\n",
    "        scores[f\"Accuracy\"] = [ metrics.accuracy_score(Y_true , prediction_function_threshold(Y_proba = Y_proba ,seuil = s)  )  for s in seuil  ]      #  Accuracy en fonction du seuil\n",
    "    if \"r\" in plot_kind :\n",
    "        scores[f\"Recall\"] = [ metrics.recall_score(Y_true , prediction_function_threshold(Y_proba = Y_proba ,seuil = s)  ) for s in seuil  ]           #  Recall en fonction du seuil\n",
    "    if \"p\" in plot_kind :\n",
    "        scores[f\"Precision\"] = [ metrics.precision_score(Y_true , prediction_function_threshold(Y_proba = Y_proba ,seuil = s)  ) for s in seuil  ]     #  Precision en fonction du seuil\n",
    "    if \"h\" in plot_kind :\n",
    "        scores[f\"Hamming Loss\"] = [ metrics.hamming_loss(Y_true , prediction_function_threshold(Y_proba = Y_proba ,seuil = s)  ) for s in seuil  ]     #  Precision en fonction du seuil\n",
    "    if \"c\" in plot_kind :\n",
    "        scores[\"Fonction Coût\"] = my_cost(Y_true , Y_proba , seuil = seuil ,scorer=False)[\"cout\"]     #  Precision en fonction du seuil\n",
    "    \n",
    "    if show_graph :\n",
    "        #  Affichage de la figure\n",
    "        plt.figure(figsize=(16,11))\n",
    "        plt.title(\"\\nF_beta, accuracy, Précision et Recall VS seuil\" , size=25)\n",
    "        plt.xlabel(\" Seuil de probabilité\" , size= 18)\n",
    "        plt.ylabel(\"SCORE\" , size = 18)\n",
    "        \n",
    "        for label , y  in scores.items()  :\n",
    "            plt.plot(seuil , y , lw = line_width ,ls = np.random.choice([\"dashed\",\"dotted\", \"dashdot\", \"solid\"]), label = f\"{label}\")\n",
    "            \n",
    "        plt.legend(loc=\"best\" , fontsize=\"xx-large\")\n",
    "        plt.show()\n",
    "        scores[\"seuil\"] = seuil\n",
    "    if give_results : return pd.DataFrame(scores ).set_index(\"seuil\")\n",
    "\n",
    "def knn_imputing_on_data(data  , save , nn = 5, m = 1500, verbose = False , AND = True) :\n",
    "    \"\"\"\n",
    "    La fonction réalise un KNN_imputing sur les données\n",
    "    \n",
    "    Paramètre : \n",
    "    -----------\n",
    "        data : pandas.core.frame.DataFrame\n",
    "            DataFrame à utiliser par la fonction pour l'exécution du KNN-imputing\n",
    "        save : Bool\n",
    "            Defini si une sauvegarde des données doit être réalisée à la fin du KNN-imputing\n",
    "        nn : int\n",
    "            defini le nombre de plus proches voisins à prendre en considération dans l'algorithme de KNN-imputing\n",
    "            la valeur par defaut est de 5\n",
    "        m : int\n",
    "            defini le nombre d'individus ou d'observations dans chaque regroupement  pour réaliser le KNN-imputing.\n",
    "            l'objectif ici est de réduire le temps d'exécution de l'algorithme est découpant les données en plusieurs données de longueur m dans lesqiels ont réalise séparement le KNN-imputing\n",
    "            La valeur par defaut est de 1500\n",
    "        verbose : bool\n",
    "            defini si l'algorithme doit écrire à chaque étape de son exécution afin que l'utilisateur puisse connaitre en temps réel l'etat d'execution de la tâche.\n",
    "            La valeur par defaut est False\n",
    "        AND : bool\n",
    "            defini le booléen à utiliser pour la condition d'une boucle de KNN-imputing, la valeur par defaut est TRUE\n",
    "        \n",
    "    Return :  pandas.core.frame.DataFrame\n",
    "    --------\n",
    "        DataFrame modifié par le KNN-imputing\n",
    "    \n",
    "    \"\"\"\n",
    "    temps_i = time.time()\n",
    "    n_classe = data.shape[0]//m\n",
    "    data[data.isin([np.inf, -np.inf]).values] = np.nan  # Transformation des valeurs infinies en valeurs manquantes\n",
    "    if AND : \n",
    "        condition = data.select_dtypes(include=[int,float]).isna().mean().mean() != 0  and \"application_train_KNN.csv\" not in os.listdir()\n",
    "    else :\n",
    "        condition = data.select_dtypes(include=[int,float]).isna().mean().mean() != 0  or \"application_train_KNN.csv\" not in os.listdir()\n",
    "    while condition :\n",
    "        knn_imputer = KNNImputer(n_neighbors=nn)  # Instantiation d'un imputer avec pour paramètre le nombre de \n",
    "        steps = np.linspace( start=0 , stop=data.shape[0] , num=n_classe  , dtype=int)\n",
    "\n",
    "        for i in range(steps.size-2) :  \n",
    "            data.select_dtypes(include=[int,float])[ steps[i]:steps[i+1] ] = knn_imputer.fit_transform(  data.select_dtypes( include=[ int , float ] )[ steps[i]:steps[i+1] ]  )\n",
    "            if i % 15 == 0 and verbose :\n",
    "                print( f\"- Etape {i} / {n_classe} -   {round(100*i*m/data.shape[0] , 2)} % terminé  - cluster de {m} lignes - KNN = {nn}\" )\n",
    "        data.select_dtypes(include=[int,float])[ steps[-2]: ] = knn_imputer.fit_transform(  data.select_dtypes( include=[ int , float ] )[ steps[-2]: ]  )\n",
    "        if verbose : print(f\"- Etape {n_classe} / {n_classe} -   100.0 % terminé  - cluster de {m} lignes\")\n",
    "        for i in data.select_dtypes(int).columns :\n",
    "            data[i] = data[i].apply(round , args= (0))  # Arrondi de tous les valeurs entières\n",
    "        data[\"CNT_FAM_MEMBERS\"] = data[\"CNT_FAM_MEMBERS\"].apply(round , args= (0))\n",
    "        \n",
    "        data[data.isin([np.inf, -np.inf]).values] = np.nan  # Transformation des valeurs infinies en valeurs manquantes\n",
    "        #data[(~np.isfinite(data.values)).values] = np.nan  # Transformation des valeurs infinies en valeurs manquantes\n",
    "        save = True\n",
    "        \n",
    "        if AND : \n",
    "            condition = data.select_dtypes(include=[int,float]).isna().mean().mean() != 0  and \"application_train_KNN.csv\" not in os.listdir()\n",
    "        else :\n",
    "            condition = data.select_dtypes(include=[int,float]).isna().mean().mean() != 0  or \"application_train_KNN.csv\" not in os.listdir()\n",
    "    print(f\"KNN imputing terminé avec les {nn} premiers voisins\\nDurée de l'execution {round(time.time()-temps_i,2)} secondes.\")\n",
    "    if save :\n",
    "        print(f\"Taille des données à la fin du traitement : {data.shape}\")\n",
    "        print(\"Sauvegarde des données en cours . . .\")\n",
    "        if \"Unnamed: 0\" in data.columns : \n",
    "            data = data.drop([\"Unnamed: 0\"], axis=1)\n",
    "        data.to_csv(\"application_train_KNN.csv\")  # Sauvegarde des données\n",
    "        print(\"Sauvegarde des données terminée avec succès.\")\n",
    "    else :\n",
    "        print(\"RAS par ici : Rien à signaler dans le coin\")\n",
    "    \n",
    "    return data , save\n",
    "\n",
    "def nouvelles_variables(data):\n",
    "    \"\"\"\n",
    "    La fonction defini de nouvelles variables dans un Dataframe à partir de varaibles pré-existante dans les données.\n",
    "    Les nouvelles variables calculées sont directement consevées dans les Dataframe fourni à la fonction\n",
    "    \n",
    "    Paramètres :\n",
    "    ------------\n",
    "        data : pandas.core.frame.DataFrame\n",
    "            DataFrame à utiliser dans la fonction pour l'éaluation de nouvelles variables\n",
    "    \n",
    "    Return :\n",
    "    --------\n",
    "        data : pandas.core.frame.DataFrame\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    \"CNT_CHILDREN\",\"CNT_FAM_MEMBERS\",\"AMT_INCOME_TOTAL\",\n",
    "    #1 - Nombre d'adultes dans la famille\n",
    "    data[\"CNT_ADULT_TOTAL\"] = data[\"CNT_FAM_MEMBERS\"] - data[\"CNT_CHILDREN\"]\n",
    "\n",
    "    #2 -  Taux de remboursement du credit\n",
    "    data[\"AMT_CREDIT_RATE_REPAYMENT\"] = data[\"AMT_ANNUITY\"]/data[\"AMT_CREDIT\"]\n",
    "\n",
    "    #3 -  Children proportion in familly\n",
    "    data[\"CHILD_PROP_IN_FAMILLY\"] = data[\"CNT_CHILDREN\"]/data[\"CNT_FAM_MEMBERS\"]\n",
    "\n",
    "    #4 -  Parts des revenus relatifs aux enfants\n",
    "    data[\"AMT_INCOME_RELATIF_TO_CHILDREN\"] = data[\"AMT_INCOME_TOTAL\"]*data[\"CNT_CHILDREN\"]/data[\"CNT_FAM_MEMBERS\"]\n",
    "    \n",
    "    #5 -  Parts des prêt à la consommation relatifs aux enfants\n",
    "    data[\"AMT_GOOD_PRICE_RELATIF_TO_CHILDREN\"] = data[\"AMT_GOODS_PRICE\"]*data[\"CNT_CHILDREN\"]/data[\"CNT_FAM_MEMBERS\"]\n",
    "\n",
    "    #6 -  revenu par membre de la famille\n",
    "    data[\"AMT_INCOME_PER_FAMLY_MEMB\"] = data[\"AMT_INCOME_TOTAL\"]/data[\"CNT_FAM_MEMBERS\"]\n",
    "\n",
    "    #7 -  revenu par adulte de la famille\n",
    "    data[\"AMT_INCOME_PER_ADULT\"] = data[\"AMT_INCOME_TOTAL\"]/data[\"CNT_ADULT_TOTAL\"]\n",
    "\n",
    "    #8 -  Revenu net de la famille\n",
    "    data[\"AMT_INCOME_NET\"] = data[\"AMT_INCOME_TOTAL\"] - data[\"AMT_ANNUITY\"]\n",
    "\n",
    "    #9 - revenu net par membre de la famille\n",
    "    data[\"AMT_INCOME_NET_PER_FAMLY_MEMB\"] = (data[\"AMT_INCOME_TOTAL\"] - data[\"AMT_ANNUITY\"])/data[\"CNT_FAM_MEMBERS\"]\n",
    "\n",
    "    #10 - revenu net par adulte de la famille\n",
    "    data[\"AMT_INCOME_NET_PER_ADULT\"] = (data[\"AMT_INCOME_TOTAL\"] - data[\"AMT_ANNUITY\"])/data[\"CNT_ADULT_TOTAL\"]\n",
    "\n",
    "    #11 - Credit à la consommation par membre de la famille\n",
    "    data[\"AMT_GOODS_PRICE_PER_FAMLY_MEMB\"] = data[\"AMT_GOODS_PRICE\"]/data[\"CNT_FAM_MEMBERS\"]\n",
    "\n",
    "    #12 - Credit à la consommation par adulte de la famille\n",
    "    data[\"AMT_GOODS_PRICE_PER_ADULT\"] = data[\"AMT_GOODS_PRICE\"]/data[\"CNT_ADULT_TOTAL\"]\n",
    "\n",
    "    #13 - Credit non dédié à la consommation\n",
    "    data[\"AMT_NOT_GOODS_PRICE\"] = data[\"AMT_CREDIT\"] - data[\"AMT_GOODS_PRICE\"]\n",
    "\n",
    "    #14 - Credit de non consommation par membre de la famille\n",
    "    data[\"AMT_NOT_GOODS_PRICE_PER_FAMLY_MEMB\"] = data[\"AMT_NOT_GOODS_PRICE\"]/data[\"CNT_FAM_MEMBERS\"]\n",
    "\n",
    "    # Credit de non consommation par adulte de la famille\n",
    "    data[\"AMT_NOT_GOODS_PRICE_PER_ADULT\"] = data[\"AMT_NOT_GOODS_PRICE\"]/data[\"CNT_ADULT_TOTAL\"]\n",
    "\n",
    "    #15 - Richesse réel de la famille\n",
    "    data[\"AMT_EXACT_RICHNESS\"] = data[\"AMT_INCOME_TOTAL\"] - data[\"AMT_CREDIT\"]\n",
    "\n",
    "    # Richesse exacte par membre de la famille\n",
    "    data[\"AMT_EXACT_RICHNESS_PER_FAMLY_MEMB\"] = data[\"AMT_EXACT_RICHNESS\"]/data[\"CNT_FAM_MEMBERS\"]\n",
    "\n",
    "    #16 - Richesse exacte par adulte de la famille\n",
    "    data[\"AMT_EXACT_RICHNESS_PER_ADULT\"] = data[\"AMT_EXACT_RICHNESS\"]/data[\"CNT_ADULT_TOTAL\"]\n",
    "\n",
    "    #17 - pourcentage de salaire sur le credit\n",
    "    data[\"AMT_INCOME_TOTAL_PER_CREDIT\"] = data[\"AMT_INCOME_TOTAL\"]/data[\"AMT_CREDIT\"]\n",
    "\n",
    "    #18 - Annuité par revenu\n",
    "    data[\"AMT_ANNUITY_PER_INCOME\"] = data[\"AMT_ANNUITY\"]/data[\"AMT_INCOME_TOTAL\"]\n",
    "\n",
    "    #19 - Annuité par revenu net\n",
    "    data[\"AMT_ANNUITY_PER_NET_INCOME\"] = data[\"AMT_ANNUITY\"]/(data[\"AMT_INCOME_TOTAL\"] - data[\"AMT_ANNUITY\"])\n",
    "\n",
    "    #20 - Annuité par richesse réelle\n",
    "    data[\"AMT_ANNUITY_PER_EXACT_RICHNESS\"] = data[\"AMT_ANNUITY\"]/data[\"AMT_EXACT_RICHNESS\"]\n",
    "\n",
    "    #21 - Age du client à la fin du prêt\n",
    "    data[\"CLIENT_AGE_AT_END_REPAYMENT\"] = data[\"DAYS_BIRTH\"] + 1.*data[\"AMT_CREDIT\"]/data[\"AMT_ANNUITY\"]\n",
    "\n",
    "    #22 - L'âge du client à son dernier emploi\n",
    "    data[\"AGE_AT_LAST_JOB\"] = data[\"DAYS_BIRTH\"]  - data[\"DAYS_EMPLOYED\"]\n",
    "\n",
    "    #23 - Poucentage des jour d'enploi par rapport à l'âge\n",
    "    data[\"DAYS_EMPLOYED_PERC\"] = data[\"DAYS_EMPLOYED\"]/data[\"DAYS_BIRTH\"]\n",
    "    \n",
    "    #24 - Credit + credit à la conssomation\n",
    "    data[\"AMT_CREDIT+GOODS_PRICE\"] = data[\"AMT_CREDIT\"] + data[\"AMT_GOODS_PRICE\"]\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65234466-ec14-4702-9eed-5f46b3fc841d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
